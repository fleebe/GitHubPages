{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b5a3b4-9701-48c7-bb4d-11cc5da28bb2",
   "metadata": {},
   "source": [
    "# Creating a tool\n",
    "\n",
    "My experiences in using AI models and tools. The aim is to build a system that enables the searching of information in google docs from google drive using RAG (Retrieval Augmented Generation). This could be extended to include searching for information in images, pdfs, spreadsheets, and microsoft documents. I want to create summaries and keywords for the documents which can be used to classify documents. \n",
    "\n",
    "The steps to do this are\n",
    "\n",
    "* access the google drive documents and for each document\n",
    "* generate a summary and list of keywords the for the document using an LLM\n",
    "* create an embedding for the documents with summary, keywords and metadata.\n",
    "* store this information in a vector database.\n",
    "* create a simple tool to use the database to find information from it for a user query.\n",
    "\n",
    "As a side effect of the work create tools that\n",
    "\n",
    "* will check that related documents are located together.\n",
    "* that folder containing the document is one of the keywords.\n",
    "* that duplicates files do not exist\n",
    "* that will update the vector database for documents that have changed since they were loaded.\n",
    "\n",
    "\n",
    "It will use Langgraph for agentic workflow, ollama:nomic-embed-text for embedding and ollama:llama3.2 as the tool model. The embeddings will be into a Chroma vector database. It will be in python.\n",
    "\n",
    "\n",
    "| Model | Source | Description | Usage |\n",
    "| :----- | :----- | :----- | :------ |\n",
    "| \"sentence-transformers/all-MiniLM-L6-v2\" | HuggingFace | Free popular, lightweight model for embeddings | Embedding |\n",
    "| \"facebook/bart-large-cnn\" | HuggingFace | Free. Use a pipeline to summarize | Summarization |\n",
    "| \"ollama:nomic-embed-text\" | Ollama | Local Embedding | Embedding |\n",
    "| \"ollama:llama3.2\" | Ollama | Local Chat model | Summarization |\n",
    "| \"llama-3.3-70b-versatile\" | Groq | Rate limited via API calls. Has tool capability | Tools, Summarization |\n",
    "\n",
    "\n",
    "\n",
    "**Example of Metadata from a folder in gdrive**\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": \"19..\",\n",
    "    \"name\": \"Coaching\",\n",
    "    \"parents\": [\"14....\"]\n",
    "}\n",
    "```\n",
    "\n",
    "**Example of Metadata from a file in gdrive**\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"createdTime\": \"2025-07-18T19:50:24.713Z\",\n",
    "    \"id\": \"1...\",\n",
    "    \"mimeType\": \"application/vnd.google-apps.document\",\n",
    "    \"modifiedTime\": \"2025-07-18T21:26:16.372Z\",\n",
    "    \"name\": \"Coaching Notes\",\n",
    "    \"owners\": [{\"displayName\": \"Phillip Lee\",\n",
    "               \"emailAddress\": \"phlee0@gmail.com\",\n",
    "               \"kind\": \"drive#user\",\n",
    "               \"me\": True,\n",
    "               \"permissionId\": \"166...\",\n",
    "               \"photoLink\": \"...\"}],\n",
    "    \"size\": \"267115\",\n",
    "    \"webViewLink\": \"https://docs.google.com/document/d/...\"\n",
    "}\n",
    "```\n",
    "\n",
    "## Gdrive/gdrive2.py\n",
    "\n",
    "It chunks documents and creates embeddings of summary and chunks for the docs in google drive. It ignores them if they exist already in the vector database. It creates metadata for the summary and chunks. The vector database uses the folder as a collection ID. This enables the searching of a particular folder only.\n",
    "\n",
    "### Summary Metadata\n",
    "\n",
    "```python\n",
    "        page_content=summary,   # text\n",
    "        id=f\"doc_{file['id']}\",\n",
    "        metadata={\n",
    "            \"type\": \"file\",\n",
    "            \"source\": file[\"name\"],\n",
    "            \"keywords\": ', '.join(keywords),\n",
    "            \"update_time\": now_str,\n",
    "            \"num_chunks\": len(summary_chunks),\n",
    "            \"id\": file.get(\"id\"),\n",
    "            \"name\": file.get(\"name\"),\n",
    "            \"mimeType\": file.get(\"mimeType\"),\n",
    "            \"webViewLink\": file.get(\"webViewLink\"),\n",
    "            \"modifiedTime\": file.get(\"modifiedTime\"),\n",
    "            \"createdTime\": file.get(\"createdTime\"),\n",
    "            \"size\": file.get(\"size\"),\n",
    "            \"owner_email\" = owners[0].get(\"emailAddress\"),\n",
    "            \"owner_name\" = owners[0].get(\"displayName\"),\n",
    "        },\n",
    "```\n",
    "\n",
    "### Chunk Metadata\n",
    "\n",
    "```python\n",
    "            page_content=chunk,  # text\n",
    "            id=f\"{file['id']}_chunk_{i}\",\n",
    "            metadata={\n",
    "                \"type\": \"chunk\",\n",
    "                \"source\": file[\"name\"],\n",
    "                \"update_time\": now_str,\n",
    "                \"chunk_size\": len(chunk.split()),\n",
    "                \"chunk_index\": i,\n",
    "            },\n",
    "```\n",
    "\n",
    "### Folder Metadata\n",
    "\n",
    "```python\n",
    "            page_content=chunk,  # text\n",
    "            id=f\"{file['id']}_chunk_{i}\",\n",
    "            metadata={\n",
    "                \"type\": \"chunk\",\n",
    "                \"source\": file[\"name\"],\n",
    "                \"update_time\": now_str,\n",
    "                \"chunk_size\": len(chunk.split()),\n",
    "                \"chunk_index\": i,\n",
    "            },\n",
    "```\n",
    "\n",
    "\n",
    "A simple rag query is used to ask questions of the documents. Will return it does not know if cannot find the information.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdcea88-3533-4003-8e5f-4bec14243d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d11ca23-62d0-4b2e-99ce-4ddba53a8505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
